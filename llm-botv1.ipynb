{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T15:06:28.171226Z","iopub.status.busy":"2024-06-14T15:06:28.170564Z","iopub.status.idle":"2024-06-14T15:06:59.014576Z","shell.execute_reply":"2024-06-14T15:06:59.013168Z","shell.execute_reply.started":"2024-06-14T15:06:28.171181Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting faiss-gpu\n","  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2+cpu)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-gpu, sentence-transformers\n","Successfully installed faiss-gpu-1.7.2 sentence-transformers-3.0.1\n","Collecting markdown2\n","  Downloading markdown2-2.4.13-py2.py3-none-any.whl.metadata (2.0 kB)\n","Downloading markdown2-2.4.13-py2.py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: markdown2\n","Successfully installed markdown2-2.4.13\n"]}],"source":["!pip install faiss-gpu transformers sentence-transformers\n","!pip install markdown2"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T15:06:59.016722Z","iopub.status.busy":"2024-06-14T15:06:59.016343Z","iopub.status.idle":"2024-06-14T15:06:59.108525Z","shell.execute_reply":"2024-06-14T15:06:59.107419Z","shell.execute_reply.started":"2024-06-14T15:06:59.016686Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded 565 pieces of text from the JSON data.\n"]}],"source":["import json\n","from markdown2 import markdown\n","from IPython.display import display, Markdown\n","\n","# Load your JSON data\n","with open('scraped_datav1.json', 'r') as f:\n","    data = json.load(f)\n","\n","# # Prepare data for embedding and retrieval\n","keys = list(data.keys())\n","texts = []\n","\n","for content in data.values():\n","    paragraphs = content.get('paragraphs', [])\n","    ordered_lists = sum(content.get('ordered_lists', []), [])\n","    unordered_lists = sum(content.get('unordered_lists', []), [])\n","    tables = sum(content.get('tables', []), [])\n","    links = sum(content.get('links', []), [])\n","    equations = content.get('equations', [])\n","    \n","    # Concatenate all text elements\n","    text_content = \" \".join(paragraphs + ordered_lists + unordered_lists + tables + equations + links)\n","    \n","#     keys.append(content['title'])  # Assuming 'title' is a key in your scraped data for section titles\n","    texts.append(text_content)\n","\n","print(f\"Loaded {len(keys)} pieces of text from the JSON data.\")\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T15:06:59.112079Z","iopub.status.busy":"2024-06-14T15:06:59.111632Z","iopub.status.idle":"2024-06-14T15:06:59.117585Z","shell.execute_reply":"2024-06-14T15:06:59.116217Z","shell.execute_reply.started":"2024-06-14T15:06:59.112038Z"},"trusted":true},"outputs":[],"source":["# texts"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T15:06:59.119189Z","iopub.status.busy":"2024-06-14T15:06:59.118856Z","iopub.status.idle":"2024-06-14T15:07:48.352983Z","shell.execute_reply":"2024-06-14T15:07:48.351733Z","shell.execute_reply.started":"2024-06-14T15:06:59.119160Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm, trange\n","2024-06-14 15:07:10.556340: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-14 15:07:10.556519: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-14 15:07:10.761015: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01b5a16f492a49fc9b52758369166427","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88e5d254b33a4375a221db9eb7dc6c91","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15946ed0ac5d46ae816add0eaf8bd6b2","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"caca43ed800040cd8278ebc457244b9e","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"075bb9682d5e450f9a714c199dd63ec9","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8deb452710f14a888f9f398f034fddd1","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d390ff4f00048a4a38c7870ff4f6539","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"425e9123f4be4a52b393ff7bd8a87515","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8fc6c8cffa674c43982545fb08b45a8e","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"435ac447fef541758efb39425b27ceaf","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a8b9d3a7c1c4a4f810fb9e08e9e3829","version_major":2,"version_minor":0},"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f76f6441324448bb66d750c5aaa4402","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/18 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da1fb8c1e272497195bd4fdb7fcb2b4f","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/18 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Generated embeddings for 565 pieces of text and 565 keys.\n"]}],"source":["from sentence_transformers import SentenceTransformer\n","\n","# Load a pre-trained model\n","model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","# Function to get embeddings\n","def get_embeddings(texts):\n","    return model.encode(texts)\n","\n","# Generate embeddings for texts and keys\n","text_embeddings = get_embeddings(texts)\n","key_embeddings = get_embeddings(keys)\n","print(f\"Generated embeddings for {len(text_embeddings)} pieces of text and {len(key_embeddings)} keys.\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T15:07:48.354893Z","iopub.status.busy":"2024-06-14T15:07:48.354250Z","iopub.status.idle":"2024-06-14T15:07:48.397488Z","shell.execute_reply":"2024-06-14T15:07:48.395394Z","shell.execute_reply.started":"2024-06-14T15:07:48.354863Z"},"trusted":true},"outputs":[],"source":["import faiss\n","import numpy as np\n","\n","# Convert embeddings to numpy array\n","text_embeddings = np.array(text_embeddings)\n","key_embeddings = np.array(key_embeddings)\n","\n","# Initialize FAISS index for texts and keys\n","text_index = faiss.IndexFlatL2(text_embeddings.shape[1])\n","key_index = faiss.IndexFlatL2(key_embeddings.shape[1])\n","\n","text_index.add(text_embeddings)\n","key_index.add(key_embeddings)\n","\n","# Save indices\n","faiss.write_index(text_index, 'text_vector_db.index')\n","faiss.write_index(key_index, 'key_vector_db.index')\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T15:07:48.399533Z","iopub.status.busy":"2024-06-14T15:07:48.399126Z","iopub.status.idle":"2024-06-14T15:07:48.462349Z","shell.execute_reply":"2024-06-14T15:07:48.461066Z","shell.execute_reply.started":"2024-06-14T15:07:48.399501Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"052d41d3a35349dfa31635817b5defbd","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Relevant sections: in-context learning, In-context learning\n","\n","Content: {'paragraphs': ['In-context learning. Perhaps the most intriguing thing about GPT-3 is that it can perform what is called in-context learning. Let’s start with an example (demo):', 'One can prompt a language model to generate a news article based on a headline (demo). Here is an example of an article that GPT-3 fabricated (everything after the bolded text):', 'We (i) see that the answer given by GPT-3 is not the most informative and (ii) perhaps want the answer directly rather than a full sentence.', 'In-context learning. Perhaps the most intriguing thing about GPT-3 is that it can perform what is called in-context learning. Let’s start with an example (demo):', 'One can prompt a language model to generate a news article based on a headline (demo). Here is an example of an article that GPT-3 fabricated (everything after the bolded text):', 'We (i) see that the answer given by GPT-3 is not the most informative and (ii) perhaps want the answer directly rather than a full sentence.'], 'tables': [], 'links': [], 'equations': [], 'ordered_lists': [], 'unordered_lists': []}\n"]}],"source":["import faiss\n","import numpy as np\n","from collections import defaultdict\n","\n","# Assuming get_embeddings and data are already defined somewhere in your code\n","\n","def process_query(query, key_index, top_k=1):\n","    # Get query embedding\n","    query_embedding = get_embeddings([query])[0].reshape(1, -1)\n","\n","    # Search for similar keys\n","    _, key_I = key_index.search(query_embedding, top_k)\n","    \n","    # Retrieve the most relevant keys and their corresponding texts\n","    result_keys = []\n","    combined_result_content = defaultdict(list)\n","\n","    for idx in key_I[0]:\n","        result_key = keys[idx]\n","        result_keys.append(result_key)\n","        result_content = data[result_key]\n","        \n","        for key, value in result_content.items():\n","            if isinstance(value, list):\n","                combined_result_content[key].extend(value)\n","            elif isinstance(value, dict):\n","                for sub_key, sub_value in value.items():\n","                    combined_result_content[key][sub_key].extend(sub_value)\n","            else:\n","                combined_result_content[key].append(value)\n","\n","    # Convert defaultdict to a regular dictionary for the final result\n","    combined_result_content = dict(combined_result_content)\n","\n","    combined_result_keys = ', '.join(result_keys)\n","    \n","    return combined_result_keys, combined_result_content\n","\n","# Load FAISS indices\n","key_index = faiss.read_index('key_vector_db.index')\n","# text_index is not used in the current implementation, so it's removed\n","\n","# Example usage\n","query = \"What is History of LLM?\"\n","result_keys, result_content = process_query(query, key_index)\n","print(f\"Relevant sections: {result_keys}\")\n","print()\n","print(\"Content:\", result_content)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T15:07:48.465232Z","iopub.status.busy":"2024-06-14T15:07:48.464070Z","iopub.status.idle":"2024-06-14T15:08:07.448607Z","shell.execute_reply":"2024-06-14T15:08:07.447456Z","shell.execute_reply.started":"2024-06-14T15:07:48.465193Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2bc3b305fbe4b959e99d8059fa64664","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b36c04663ff4a23a8ff0598e4bd497d","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"adfaa10f8bff43fc920874dedcb24f4b","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9177cf26a3d45b08ffb6953072ababd","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e39b34ecd60435c865b021023b5ce60","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1cb680c729d2482091296277e723a4ef","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3338e02f6ab74d969782a699cca9ac4f","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import pipeline\n","\n","# Load a text generation pipeline (e.g., GPT-2)\n","generator = pipeline('text-generation', model='gpt2')\n","\n","def generate_structured_response(query, result_key, result_content):\n","    # Create a structured prompt\n","    prompt = f\"Question: {query}\\n\\n\"\n","    prompt += f\"Section: {result_key}\\n\\n\"\n","    \n","    # Add content to the prompt\n","    if result_content.get('paragraphs'):\n","        prompt += \"Paragraphs:\\n\" + \"\\n\".join(result_content['paragraphs']) + \"\\n\\n\"\n","    if result_content.get('ordered_lists'):\n","        prompt += \"Ordered Lists:\\n\" + \"\\n\".join([\"\\n\".join(ol) for ol in result_content['ordered_lists']]) + \"\\n\\n\"\n","    if result_content.get('unordered_lists'):\n","        prompt += \"Unordered Lists:\\n\" + \"\\n\".join([\"\\n\".join(ul) for ul in result_content['unordered_lists']]) + \"\\n\\n\"\n","    if result_content.get('tables'):\n","        prompt += \"Tables:\\n\" + \"\\n\".join([\"\\n\".join(table) for table in result_content['tables']]) + \"\\n\\n\"\n","    if result_content.get('links'):\n","        prompt += \"Links:\\n\" + \"\\n\".join(result_content['links']) + \"\\n\\n\"\n","    if result_content.get('equations'):\n","        prompt += \"Equations:\\n\" + \"\\n\".join(result_content['equations']) + \"\\n\\n\"\n","    \n","    # Add a closing statement\n","    prompt += \"Answer is :\"\n","    \n","    # Generate response\n","    response = generator(prompt[:300], max_length=300, num_return_sequences=1,truncation=True,pad_token_id=50256)\n","    generated_text = response[0]['generated_text']\n","\n","    return generated_text\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T15:08:07.460364Z","iopub.status.busy":"2024-06-14T15:08:07.459947Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac985dc6e1ef4bea9c8ce7828d5f8c57","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Generate structured response\n","query = \"What is a language model?\"\n","result_key, result_content = process_query(query, key_index)\n","\n","# Generate structured response\n","generated_text = generate_structured_response(query, result_key, result_content)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(generated_text)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5210665,"sourceId":8691921,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
